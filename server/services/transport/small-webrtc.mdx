---
title: "SmallWebRTCTransport"
description: "A lightweight WebRTC transport for peer-to-peer audio and video communication in Pipecat"
---

## Overview

`SmallWebRTCTransport` enables peer-to-peer WebRTC connections between clients and your Pipecat application. It implements bidirectional audio and video streaming using WebRTC for real-time communication.

This transport is intended for lightweight implementations, particularly for local development and testing.

<Warning>
  `SmallWebRTCTransport` is best used for testing and development. For
  production deployments with scale, consider using the
  [DailyTransport](/server/services/transport/daily), as it has global,
  low-latency infrastructure.
</Warning>

## Installation

To use `SmallWebRTCTransport`, install the required dependencies:

```bash
pip install pipecat-ai[webrtc]
```

## Class Reference

### SmallWebRTCConnection

`SmallWebRTCConnection` manages the WebRTC connection details, peer connection state, and ICE candidates. It handles the signaling process and media tracks.

```python
SmallWebRTCConnection(ice_servers=None)
```

<ParamField path="ice_servers" type="list[str]" optional>
  List of STUN/TURN server URLs for ICE connection establishment.
</ParamField>

#### Methods

<ResponseField name="initialize" type="async method">
  Initialize the connection with a client's SDP offer.

**Parameters:**

- `sdp`: String containing the Session Description Protocol data from client's offer
- `type`: String representing the SDP message type (typically "offer")

```python
await webrtc_connection.initialize(sdp=client_sdp, type="offer")
```

</ResponseField>

<ResponseField name="connect" type="async method">
  Establish the WebRTC peer connection after initialization.

```python
await webrtc_connection.connect()
```

</ResponseField>

<ResponseField name="close" type="async method">
  Close the WebRTC peer connection.

```python
await webrtc_connection.close()
```

</ResponseField>

<ResponseField name="renegotiate" type="async method">
  Handle connection renegotiation requests.

**Parameters:**

- `sdp`: String containing the Session Description Protocol data for renegotiation
- `type`: String representing the SDP message type
- `restart_pc`: Boolean indicating whether to completely restart the peer connection (default: False)

```python
await webrtc_connection.renegotiate(sdp=new_sdp, type="offer", restart_pc=False)
```

</ResponseField>

<ResponseField name="get_answer" type="method">
  Retrieve the SDP answer to send back to the client.
  
  Returns a dictionary with `sdp`, `type`, and `pc_id` fields.

```python
answer = webrtc_connection.get_answer()
# Returns: {"sdp": "...", "type": "answer", "pc_id": "..."}
```

</ResponseField>

<ResponseField name="send_app_message" type="method">
  Send an application message to the client.

**Parameters:**

- `message`: The message to send (will be JSON serialized)

```python
webrtc_connection.send_app_message({"action": "greeting", "text": "Hello!"})
```

</ResponseField>

<ResponseField name="is_connected" type="method">
  Check if the connection is active.

```python
if webrtc_connection.is_connected():
    print("Connection is active")
```

</ResponseField>

<ResponseField name="audio_input_track" type="method">
  Get the audio input track from the client.

```python
audio_track = webrtc_connection.audio_input_track()
```

</ResponseField>

<ResponseField name="video_input_track" type="method">
  Get the video input track from the client.

```python
video_track = webrtc_connection.video_input_track()
```

</ResponseField>

<ResponseField name="ask_to_renegotiate" type="method">
  Request the client to initiate connection renegotiation.

```python
webrtc_connection.ask_to_renegotiate()
```

</ResponseField>

<ResponseField name="event_handler" type="decorator">
  Register an event handler for connection events.

**Events:**

- `"app-message"`: Called when a message is received from the client
- `"connecting"`: Called when connection is being established
- `"connected"`: Called when connection is established
- `"disconnected"`: Called when connection is lost
- `"closed"`: Called when connection is closed
- `"failed"`: Called when connection fails
- `"new"`: Called when a new connection is created

```python
@webrtc_connection.event_handler("connected")
async def on_connected(connection):
    print(f"WebRTC connection established")
```

</ResponseField>

### SmallWebRTCTransport

`SmallWebRTCTransport` is the main transport class that manages both input and output transports for WebRTC communication.

```python
SmallWebRTCTransport(
    webrtc_connection: SmallWebRTCConnection,
    params: TransportParams,
    input_name: Optional[str] = None,
    output_name: Optional[str] = None
)
```

<ParamField path="webrtc_connection" type="SmallWebRTCConnection" required>
  An instance of `SmallWebRTCConnection` that manages the WebRTC connection
</ParamField>

<ParamField path="params" type="TransportParams" required>
  Configuration parameters for the transport
  <Expandable title="TransportParams properties">
    <ParamField path="audio_in_enabled" type="bool" default={false}>
      Enable audio input from the WebRTC client
    </ParamField>

    <ParamField path="audio_out_enabled" type="bool" default={false}>
      Enable audio output to the WebRTC client
    </ParamField>

    <ParamField path="audio_in_sample_rate" type="int" optional>
      Sample rate for incoming audio (Hz)
    </ParamField>

    <ParamField path="audio_out_sample_rate" type="int" optional>
      Sample rate for outgoing audio (Hz)
    </ParamField>

    <ParamField path="audio_in_channels" type="int" default={1}>
      Number of audio input channels (1 for mono, 2 for stereo)
    </ParamField>

    <ParamField path="audio_out_channels" type="int" default={1}>
      Number of audio output channels (1 for mono, 2 for stereo)
    </ParamField>

    <ParamField path="camera_in_enabled" type="bool" default={false}>
      Enable video input from the WebRTC client
    </ParamField>

    <ParamField path="camera_out_enabled" type="bool" default={false}>
      Enable video output to the WebRTC client
    </ParamField>

    <ParamField path="camera_out_width" type="int" default={640}>
      Width of outgoing video
    </ParamField>

    <ParamField path="camera_out_height" type="int" default={480}>
      Height of outgoing video
    </ParamField>

    <ParamField path="camera_out_framerate" type="int" default={30}>
      Framerate of outgoing video
    </ParamField>

    <ParamField path="vad_enabled" type="bool" default={false}>
      Enable Voice Activity Detection
    </ParamField>

    <ParamField path="vad_analyzer" type="VADAnalyzer" optional>
      Custom VAD analyzer implementation
    </ParamField>

    <ParamField path="vad_audio_passthrough" type="bool" default={false}>
      Pass audio through even when VAD is enabled
    </ParamField>

  </Expandable>
</ParamField>

<ParamField path="input_name" type="str" optional>
  Optional name for the input transport
</ParamField>

<ParamField path="output_name" type="str" optional>
  Optional name for the output transport
</ParamField>

#### Methods

<ResponseField name="input" type="method">
  Returns the input transport instance.

```python
input_transport = webrtc_transport.input()
```

</ResponseField>

<ResponseField name="output" type="method">
  Returns the output transport instance.

```python
output_transport = webrtc_transport.output()
```

</ResponseField>

#### Event Handlers

<ResponseField name="on_app_message" type="async callback">
  Called when receiving application messages from the client.

**Parameters:**

- `message`: The received message

```python
@webrtc_transport.event_handler("on_app_message")
async def on_app_message(message):
    print(f"Received message: {message}")
```

</ResponseField>

<ResponseField name="on_client_connected" type="async callback">
  Called when a client successfully connects.

**Parameters:**

- `transport`: The SmallWebRTCTransport instance
- `webrtc_connection`: The connection that was established

```python
@webrtc_transport.event_handler("on_client_connected")
async def on_client_connected(transport, webrtc_connection):
    print(f"Client connected")
```

</ResponseField>

<ResponseField name="on_client_disconnected" type="async callback">
  Called when a client disconnects.

**Parameters:**

- `transport`: The SmallWebRTCTransport instance
- `webrtc_connection`: The connection that was disconnected

```python
@webrtc_transport.event_handler("on_client_disconnected")
async def on_client_disconnected(transport, webrtc_connection):
    print(f"Client disconnected")
```

</ResponseField>

<ResponseField name="on_client_closed" type="async callback">
  Called when a client connection is closed.

**Parameters:**

- `transport`: The SmallWebRTCTransport instance
- `webrtc_connection`: The connection that was closed

```python
@webrtc_transport.event_handler("on_client_closed")
async def on_client_closed(transport, webrtc_connection):
    print(f"Client connection closed")
```

</ResponseField>

## Basic Usage

This basic usage example shows the transport specific parts of a bot.py file required to configure your bot:

```python
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.pipeline.pipeline import Pipeline
from pipecat.transports.base_transport import TransportParams
from pipecat.transports.network.small_webrtc import SmallWebRTCTransport

async def run_bot(webrtc_connection):
    # Create the WebRTC transport with the provided connection
    transport = SmallWebRTCTransport(
        webrtc_connection=webrtc_connection,
        params=TransportParams(
            audio_in_enabled=True,   # Accept audio from the client
            audio_out_enabled=True,  # Send audio to the client
            vad_enabled=True,        # Enable Voice Activity Detection
            vad_analyzer=SileroVADAnalyzer(),
            vad_audio_passthrough=True,
        ),
    )

    # Set up your services and context

    # Create the pipeline
    pipeline = Pipeline([
        transport.input(),              # Receive audio from client
        stt,                            # Convert speech to text
        context_aggregator.user(),      # Add user messages to context
        llm,                            # Process text with LLM
        tts,                            # Convert text to speech
        transport.output(),             # Send audio responses to client
        context_aggregator.assistant(), # Add assistant responses to context
    ])

    # Register event handlers
    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info("Client connected")
        # Start the conversation when client connects
        await task.queue_frames([context_aggregator.user().get_context_frame()])

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info("Client disconnected")

    @transport.event_handler("on_client_closed")
    async def on_client_closed(transport, client):
        logger.info("Client closed")
        await task.cancel()
```

## Examples

To see a complete implementation, check out the following examples:

<CardGroup>
  <Card
    title="Video Transform"
    icon="camera"
    href="https://github.com/pipecat-ai/pipecat/tree/main/examples/p2p-webrtc/video-transform"
  >
    Demonstrates real-time video processing using WebRTC transport
  </Card>
  <Card
    title="Voice Agent"
    icon="microphone"
    href="https://github.com/pipecat-ai/pipecat/tree/main/examples/p2p-webrtc/voice-agent"
  >
    Implements a voice assistant using WebRTC for audio communication
  </Card>
</CardGroup>

## Media Handling

### Audio

Audio is processed in 20ms chunks by default. The transport handles audio format conversion and resampling as needed:

- Input audio is processed at 16kHz (mono) to be compatible with speech recognition services
- Output audio can be configured to match your application's requirements, but it must be mono, 16-bit PCM audio

### Video

Video is streamed using RGB format by default. The transport provides:

- Frame conversion between different color formats (RGB, YUV, etc.)
- Configurable resolution and framerate

## Advanced Configuration

### ICE Servers

For better connectivity, especially when testing across different networks, you can provide STUN servers:

```python
webrtc_connection = SmallWebRTCConnection(
    ice_servers=["stun:stun.l.google.com:19302", "stun:stun1.l.google.com:19302"]
)
```

## Troubleshooting

If clients have trouble connecting or streaming:

1. Check browser console for WebRTC errors
2. Ensure you're using HTTPS in production (required for WebRTC)
3. For testing across networks, consider using Daily which provides TURN servers
4. Verify browser permissions for camera and microphone
