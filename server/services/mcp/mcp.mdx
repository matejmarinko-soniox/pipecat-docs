---
title: "MCPClient"
description: "Service to connect to MCP (Model Context Protocol) servers"
---

## Overview

`MCPClient` provides a way to access MCP servers. See [MCP](https://github.com/modelcontextprotocol) for more details. 

## Installation

To use `MCPClient`, install the required dependencies:

```bash
pip install "pipecat-ai[mcp]"
```

You may also need to environment variables as required by the specific MCP server to which you are connecting.

## Configuration

### Constructor Parameters

You can connect to your MCP server via Stdio or SSE transport. See [here](https://modelcontextprotocol.io/docs/concepts/transports#built-in-transport-types) for more documentation.

<ParamField path="server_params" type="str" required>
    "https://your.mcp.server/sse"
</ParamField>

~OR~

<ParamField path="server_params" type="StdioServerParameters" required>
    StdioServerParameters(
        command="python",  # Executable
        args=["example_server.py"],  # Optional command line arguments
        env=None,  # Optional environment variables
    )
</ParamField>

### Input Parameters

See more information regarding server params [here](https://github.com/modelcontextprotocol/python-sdk?tab=readme-ov-file#writing-mcp-clients).

## Usage Example

```python
...
from mcp import StdioServerParameters
from pipecat.services.mcp_service import MCPClient
...

llm = ...

# Configure service
mcp = MCPClient(
        server_params=StdioServerParameters(
            command=shutil.which("npx"),
            args=["-y", "@name/mcp-server-name@latest"],
            env={"ENV_API_KEY": "<env_api_key>"},
        )
    )

# Create tools schema from the MCP server and register them with llm
tools = await mcp.register_tools(llm)

# Create context with system message and tools
context = OpenAILLMContext(
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant in a voice conversation. You have access to MCP tools. Keep responses concise."
        }
    ],
    tools=tools
)

# Create context aggregator for message handling
context_aggregator = llm.create_context_aggregator(context)

# Set up pipeline
pipeline = Pipeline([
    transport.input(),
    context_aggregator.user(),
    llm,
    tts,
    transport.output(),
    context_aggregator.assistant()
])

# Create and configure task
task = PipelineTask(
    pipeline,
    params=PipelineParams(
        allow_interruptions=True,
        enable_metrics=True,
        enable_usage_metrics=True,
    ),
)
```

## Methods

<ResponseField name="register_tools" type="async method">
  Converts MCP tools to Pipecat-friendly function definitions and registers the functions with the llm.

```python
async def register_tools(self, llm) -> ToolsSchema:
```

## Additional documentation

<Note>
  See [MCP's docs](https://github.com/modelcontextprotocol/python-sdk) for MCP related updates.
</Note>

