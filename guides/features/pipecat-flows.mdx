---
title: "Pipecat Flows"
description: "Learn how to create structured conversations using Pipecatâ€™s flow system"
---

Pipecat Flows provides a framework for building structured conversations in your AI applications. It enables you to create both predefined conversation paths and dynamically generated flows while handling the complexities of state management and LLM interactions.

The framework consists of:

- A Python module for building conversation flows with Pipecat
- A visual editor for designing and exporting flow configurations

## Key Concepts

- **Nodes**: Represent conversation states with specific messages and available functions
- **Messages**: Set the role and tasks for each node
- **Functions**: Define actions and transitions (Node functions for operations, Edge functions for transitions)
- **Actions**: Execute operations during state transitions (pre/post actions)
- **State Management**: Handle conversation state and data persistence

## Example Flows

<CardGroup>
  <Card
    title="Movie Explorer (Static)"
    icon="film"
    href="https://github.com/pipecat-ai/pipecat-flows/blob/main/examples/static/movie_explorer_openai.py"
  >
    A static flow demonstrating movie exploration using OpenAI. Shows real API
    integration with TMDB, structured data collection, and state management.
  </Card>

  <Card
    title="Insurance Policy (Dynamic)"
    icon="shield"
    href="https://github.com/pipecat-ai/pipecat-flows/blob/main/examples/dynamic/insurance_gemini.py"
  >
    A dynamic flow using Google Gemini that adapts policy recommendations based
    on user responses. Demonstrates runtime node creation and conditional paths.
  </Card>
</CardGroup>

<Note>
  These examples are fully functional and can be run locally. Make sure you have
  the required dependencies installed and API keys configured.
</Note>

## When to Use Static vs Dynamic Flows

**Static Flows** are ideal when:

- Conversation structure is known upfront
- Paths follow predefined patterns
- Flow can be fully configured in advance
- Example: Customer service scripts, intake forms

**Dynamic Flows** are better when:

- Paths depend on external data
- Flow structure needs runtime modification
- Complex decision trees are involved
- Example: Personalized recommendations, adaptive workflows

# Installation

If you're already using Pipecat:

```bash
pip install pipecat-ai-flows
```

If you're starting fresh:

```bash
# Basic installation
pip install pipecat-ai-flows

# Install Pipecat with specific LLM provider options:
pip install "pipecat-ai[daily,openai,deepgram]"     # For OpenAI
pip install "pipecat-ai[daily,anthropic,deepgram]"  # For Anthropic
pip install "pipecat-ai[daily,google,deepgram]"     # For Google
```

ðŸ’¡ Want to design your flows visually? Try the [online Flow Editor](https://flows.pipecat.ai)

# Core Concepts

## Designing Conversation Flows

Functions in Pipecat Flows serve two key purposes:

- Processing data (likely by interfacing with external systems and APIs)
- Advancing the conversation to the next node

Each function can do one or both.

LLMs decide when to run each function, via their function calling (or tool calling) mechanism.

### Defining a Function

A function is expected to return a `(result, next_node)` tuple. More precisely, itâ€™s expected to return:

```python
# (result, next_node)
Tuple[Optional[FlowResult], Optional[Union[NodeConfig, str]]]
```

If the function processes data, it should return a non-`None` value for the first element of the tuple. This value should be a `FlowResult` or subclass.

If the function advances the conversation to the next node, it should return a non-`None` value for the second element of the tuple. This value can be either:

- A `NodeConfig` defining the next node (for dynamic flows)
- A string identifying the next node (for static flows)

### Example Function

```python
from pipecat_flows import FlowArgs, FlowManager, FlowResult, NodeConfig

async def check_availability(args: FlowArgs, flow_manager: FlowManager) -> tuple[FlowResult, NodeConfig]:
    # Read arguments
    date = args["date"]
    time = args["time"]

    # Read previously-stored data
    party_size = flow_manager.state.get("party_size")

    # Use flow_manager for immediate user feedback
    await flow_manager.task.queue_frame(TTSSpeakFrame("Checking our reservation system..."))

    # Store data in flow state for later use
    flow_manager.state["requested_date"] = date

    # Interface with reservation system
    is_available = await reservation_system.check_availability(date, time, party_size)

    # Assemble result
    result = { "status": "success", "available": available }

    # Decide which node to go to next
    if is_available:
        next_node = create_confirmation_node()
    else:
        next_node = create_no_availability_node()

    # Return both result and next node
    return result, next_node
```

## Node Structure

Each node in your flow represents a conversation state and consists of three main components:

### Messages

Nodes use two types of messages to control the conversation:

1. **Role Messages**: Define the bot's personality or role (optional)

```python
"role_messages": [
    {
        "role": "system",
        "content": "You are a friendly pizza ordering assistant. Keep responses casual and upbeat."
    }
]
```

2. **Task Messages**: Define what the bot should do in the current node

```python
"task_messages": [
    {
        "role": "system",
        "content": "Ask the customer which pizza size they'd like: small, medium, or large."
    }
]
```

Role messages are typically defined in your initial node and inherited by subsequent nodes, while task messages are specific to each node's purpose.

### Functions

Functions in Pipecat Flows can:

1. Process data
2. Specify node transitions
3. Do both

This leads to two conceptual types of functions:

- **Node functions**, which only process data.
- **Edge functions**, which also (or only) transition to the next node.

The function itself ([which you can read more about here](#defining-a-function)) is usually wrapped in a function configuration, which also contains some metadata about the function.

#### Function Configuration

Pipecat Flows supports three ways of specifying function configuration:

1. Provider-specific dictionary format

```python
# Dictionary format
{
    "type": "function",
    "function": {
        "name": "select_size",
        "handler": select_size,
        "description": "Select pizza size",
        "parameters": {
            "type": "object",
            "properties": {
                "size": {"type": "string", "enum": ["small", "medium", "large"]}
            }
        },
    }
}
```

2. FlowsFunctionSchema

```python
# Using FlowsFunctionSchema
from pipecat_flows import FlowsFunctionSchema

size_function = FlowsFunctionSchema(
    name="select_size",
    description="Select pizza size",
    properties={
        "size": {"type": "string", "enum": ["small", "medium", "large"]}
    },
    required=["size"],
    handler=select_size
)

# Use in node configuration
node_config = {
    "task_messages": [...],
    "functions": [size_function]
}
```

The `FlowsFunctionSchema` approach provides some advantages over the provider-specific dictionary format:

- Consistent structure across LLM providers
- Simplified parameter definition
- Cleaner, more readable code

<Note>
  Both dictionary and `FlowsFunctionSchema` approaches are fully supported.
  `FlowsFunctionSchema` is recommended for new projects as it provides better
  type checking and a provider-independent format.
</Note>

3. Direct function usage (auto-configuration)

This approach lets you bypass specifying a standalone function configuration.

Instead, relevant function metadata is automatically extracted from the function's signature and docstring:

- `name`
- `description`
- `properties` (including individual property `description`s)
- `required`

Note that the function signature is a bit different when using direct functions. The first parameter is the `FlowManager`, followed by any others necessary for the function.

```python
from pipecat_flows import FlowManager, FlowResult

async def select_pizza_order(
    flow_manager: FlowManager,
    size: str,
    pizza_type: str,
    additional_toppings: list[str] = [],
) -> tuple[FlowResult, str]:
    """
    Record the pizza order details.

    Args:
        size (str): Size of the pizza. Must be one of "small", "medium", or "large".
        pizza_type (str): Type of pizza. Must be one of "pepperoni", "cheese", "supreme", or "vegetarian".
        additional_toppings (list[str]): List of additional toppings. Defaults to empty list.
    """
    ...

# Use in node configuration
node_config = {
    "task_messages": [...],
    "functions": [select_pizza_order]
}
```

#### Node Functions

Functions that process data within a single conversational state, without switching nodes. When called, they:

- Execute their `handler` to do the data processing (typically by interfacing with an external system or API)
- Trigger an immediate LLM completion with the result

```python
from pipecat_flows import FlowArgs, FlowManager, FlowResult

async def select_size(args: FlowArgs, flow_manager: FlowManager) -> tuple[FlowResult, None]:
    """Process pizza size selection."""
    size = args["size"]
    await ordering_system.record_size_selection(size)
    return {
        "status": "success",
        "size": size
    }, None

# Function configuration
{
    "type": "function",
    "function": {
        "name": "select_size",
        "handler": select_size,
        "description": "Select pizza size",
        "parameters": {
            "type": "object",
            "properties": {
                "size": {"type": "string", "enum": ["small", "medium", "large"]}
            }
        },
    }
}
```

#### Edge Functions

Functions that specify a transition between nodes (optionally processing data first). When called, they:

- Execute their `handler` to do any data processing (optional) and determine the next node
- Add the function result to the LLM context
- Trigger LLM completion after both the function result and the next node's messages are in the context

```python
from pipecat_flows import FlowArgs, FlowManager, FlowResult

async def select_size(args: FlowArgs, flow_manager: FlowManager) -> tuple[FlowResult, NodeConfig]:
    """Process pizza size selection."""
    size = args["size"]
    await ordering_system.record_size_selection(size)
    result = {
        "status": "success",
        "size": size
    }
    next_node = create_confirmation_node()
    return result, next_node

# Function configuration
{
    "type": "function",
    "function": {
        "name": "select_size",
        "handler": select_size,
        "description": "Select pizza size",
        "parameters": {
            "type": "object",
            "properties": {
                "size": {"type": "string", "enum": ["small", "medium", "large"]}
            }
        },
    }
}
```

### Actions

Actions are operations that execute as part of the lifecycle of a node, with two distinct timing options:

- Pre-actions: execute when entering the node, before the LLM completion
- Post-actions: execute after the LLM completion

#### Pre-Actions

Execute when entering the node, before LLM inference. Useful for:

- Providing immediate feedback while waiting for LLM responses
- Bridging gaps during longer function calls
- Setting up state or context

```python
"pre_actions": [
    {
        "type": "tts_say",
        "text": "Hold on a moment..."  # Immediate feedback during processing
    }
],
```

Note that when the node is configured with `respond_immediately: False`, the `pre_actions` still run when entering the node, which may be well before LLM inference, depending on how long the user takes to speak first.

<Tip>
  Avoid mixing `tts_say` actions with chat completions as this may result in a
  conversation flow that feels unnatural. `tts_say` are best used as filler
  words when the LLM will take time to generate an completion.
</Tip>

#### Post-Actions

Execute after LLM inference completes. Useful for:

- Cleanup operations
- State finalization
- Ensuring proper sequence of operations

```python
"post_actions": [
    {
        "type": "end_conversation"  # Ensures TTS completes before ending
    }
]
```

Note that when the node is configured with `respond_immediately: False`, the `post_actions` still only run after the first LLM inference, which may be a while depending on how long the user takes to speak first.

#### Timing Considerations

- **Pre-actions**: Execute immediately, before any LLM processing begins
- **LLM Inference**: Processes the node's messages and functions
- **Post-actions**: Execute after LLM processing and TTS completion

For example, when using `end_conversation` as a post-action, the sequence is:

1. LLM generates response
2. TTS speaks the response
3. End conversation action executes

This ordering ensures proper completion of all operations.

#### Action Types

Flows comes equipped with pre-canned actions and you can also define your own action behavior. See the [reference docs](/server/frameworks/flows/pipecat-flows#actions) for more information.

## Deciding Who Speaks First

For each node in the conversation, you can decide whether the LLM should respond immediately upon entering the node (the default behavior) or whether the LLM should wait for the user to speak first before responding. You do this using the `respond_immediately` field.

<Tip>
  `respond_immediately=False` may be particularly useful in the very first node,
  especially in outbound-calling cases where the user has to first answer the
  phone to trigger the conversation.
</Tip>

```python
NodeConfig(
    task_messages=[
        {
            "role": "system",
            "content": "Warmly greet the customer and ask how many people are in their party. This is your only job for now; if the customer asks for something else, politely remind them you can't do it.",
        }
    ],
    respond_immediately=False,
    # ... other fields
)
```

<Warning>
  Keep in mind that if you specify `respond_immediately=False`, the user may not
  be aware of the conversational task at hand when entering the node (the bot
  hasn't told them yet). While it's always important to have guardrails in your
  node messages to keep the conversation on topic, letting the user speak first
  makes it even more so.
</Warning>

## Context Management

Pipecat Flows provides three strategies for managing conversation context during node transitions:

### Context Strategies

- **APPEND** (default): Adds new messages to the existing context, maintaining the full conversation history
- **RESET**: Clears the context and starts fresh with the new node's messages
- **RESET_WITH_SUMMARY**: Resets the context but includes an AI-generated summary of the previous conversation

### Configuration

Context strategies can be configured globally or per-node:

```python
from pipecat_flows import ContextStrategy, ContextStrategyConfig

# Global strategy configuration
flow_manager = FlowManager(
    task=task,
    llm=llm,
    context_aggregator=context_aggregator,
    context_strategy=ContextStrategyConfig(
        strategy=ContextStrategy.RESET_WITH_SUMMARY,
        summary_prompt="Summarize the key points discussed so far, focusing on decisions made and important information collected."
    )
)

# Per-node strategy configuration
node_config = {
    "task_messages": [...],
    "functions": [...],
    "context_strategy": ContextStrategyConfig(
        strategy=ContextStrategy.RESET_WITH_SUMMARY,
        summary_prompt="Provide a concise summary of the customer's order details and preferences."
    )
}
```

### Strategy Selection

Choose your strategy based on your conversation needs:

- Use **APPEND** when full conversation history is important
- Use **RESET** when previous context might confuse the current node's purpose
- Use **RESET_WITH_SUMMARY** for long conversations where key points need to be preserved

<Note>
  When using RESET_WITH_SUMMARY, if summary generation fails or times out, the
  system automatically falls back to RESET strategy for resilience.
</Note>

## State Management

The `state` variable in FlowManager is a shared dictionary that persists throughout the conversation. Think of it as a conversation memory that lets you:

- Store user information
- Track conversation progress
- Share data between nodes
- Inform decision-making

Here's a practical example of a pizza ordering flow:

```python
# Store user choices as they're made
async def select_size(args: FlowArgs) -> tuple[FlowResult, str]:
    """Handle pizza size selection."""
    size = args["size"]

    # Initialize order in state if it doesn't exist
    if "order" not in flow_manager.state:
        flow_manager.state["order"] = {}

    # Store the selection
    flow_manager.state["order"]["size"] = size

    return {"status": "success", "size": size}, "toppings"

async def select_toppings(args: FlowArgs) -> tuple[FlowResult, str]:
    """Handle topping selection."""
    topping = args["topping"]

    # Get existing order and toppings
    order = flow_manager.state.get("order", {})
    toppings = order.get("toppings", [])

    # Add new topping
    toppings.append(topping)
    order["toppings"] = toppings
    flow_manager.state["order"] = order

    return {"status": "success", "toppings": toppings}, "finalize"

async def finalize_order(args: FlowArgs) -> tuple[FlowResult, str]:
    """Process the complete order."""
    order = flow_manager.state.get("order", {})

    # Validate order has required information
    if "size" not in order:
        return {"status": "error", "error": "No size selected"}

    # Calculate price based on stored selections
    size = order["size"]
    toppings = order.get("toppings", [])
    price = calculate_price(size, len(toppings))

    return {
        "status": "success",
        "summary": f"Ordered: {size} pizza with {', '.join(toppings)}",
        "price": price
    }, "end"
```

In this example:

1. `select_size` initializes the order and stores the size
2. `select_toppings` builds a list of toppings
3. `finalize_order` uses the stored information to process the complete order

The state variable makes it easy to:

- Build up information across multiple interactions
- Access previous choices when needed
- Validate the complete order
- Calculate final results

This is particularly useful when information needs to be collected across multiple conversation turns or when later decisions depend on earlier choices.

## LLM Provider Support

Pipecat Flows automatically handles format differences between LLM providers:

### OpenAI Format

```python
"functions": [{
    "type": "function",
    "function": {
        "name": "function_name",
        "handler": select_size,
        "description": "description",
        "parameters": {...}
    }
}]
```

### Anthropic Format

```python
"functions": [{
    "name": "function_name",
    "handler": select_size,
    "description": "description",
    "input_schema": {...}
}]
```

### Google (Gemini) Format

```python
"functions": [{
    "function_declarations": [{
        "name": "function_name",
        "handler": select_size,
        "description": "description",
        "parameters": {...}
    }]
}]
```

<Note>
  You don't need to handle these differences manually - Pipecat Flows adapts
  your configuration to the correct format based on your LLM provider.
</Note>
# Implementation Approaches

## Static Flows

Static flows use a configuration-driven approach where the entire conversation structure is defined upfront.

### Basic Setup

```python
from pipecat_flows import FlowManager

# Define flow configuration
flow_config = {
    "initial_node": "greeting",
    "nodes": {
        "greeting": {
            "role_messages": [...],
            "task_messages": [...],
            "functions": [...]
        }
    }
}

# Initialize flow manager with static configuration
flow_manager = FlowManager(
    task=task,
    llm=llm,
    context_aggregator=context_aggregator,
    flow_config=flow_config
)

@transport.event_handler("on_first_participant_joined")
async def on_first_participant_joined(transport, participant):
    await transport.capture_participant_transcription(participant["id"])
    await flow_manager.initialize()
```

### Example FlowConfig

```python
flow_config = {
    "initial_node": "start",
    "nodes": {
        "start": {
            "role_messages": [
                {
                    "role": "system",
                    "content": "You are an order-taking assistant. You must ALWAYS use the available functions to progress the conversation. This is a phone conversation and your responses will be converted to audio. Keep the conversation friendly, casual, and polite. Avoid outputting special characters and emojis.",
                }
            ],
            "task_messages": [
                {
                    "role": "system",
                    "content": "You are an order-taking assistant. Ask if they want pizza or sushi."
                }
            ],
            "functions": [
                {
                    "type": "function",
                    "function": {
                        "name": "choose_pizza",
                        "handler": choose_pizza, # Returns [None, "pizza_order"]
                        "description": "User wants pizza",
                        "parameters": {"type": "object", "properties": {}}
                    }
                }
            ]
        },
        "pizza_order": {
            "task_messages": [...],
            "functions": [
                {
                    "type": "function",
                    "function": {
                        "name": "select_size",
                        "handler": select_size, # Returns [FlowResult, "toppings"]
                        "description": "Select pizza size",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "size": {"type": "string", "enum": ["small", "medium", "large"]}
                            }
                        }
                    }
                }
            ]
        }
    }
}
```

## Dynamic Flows

Dynamic flows create and modify conversation paths at runtime based on data or business logic.

### Example Implementation

Here's a complete example of a dynamic insurance quote flow:

```python
from pipecat_flows import FlowManager, FlowArgs, FlowResult

# Define handlers and transitions
async def collect_age(args: FlowArgs, flow_manager: FlowManager) -> tuple[AgeResult, NodeConfig]:
    """Process age collection."""
    age = args["age"]

    # Assemble result
    result = AgeResult(status="success", age=age)

    # Decide which node to go to next
    if age < 25:
        await flow_manager.set_node_from_config(create_young_adult_node())
    else:
        await flow_manager.set_node_from_config(create_standard_node())

    return result, age

# Node creation functions
def create_initial_node() -> NodeConfig:
    """Create initial age collection node."""
    return {
        "name": "initial",
        "role_messages": [
            {
                "role": "system",
                "content": "You are an insurance quote assistant."
            }
        ],
        "task_messages": [
            {
                "role": "system",
                "content": "Ask for the customer's age."
            }
        ],
        "functions": [
            {
                "type": "function",
                "function": {
                    "name": "collect_age",
                    "handler": collect_age,
                    "description": "Collect customer age",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "age": {"type": "integer"}
                        }
                    }
                }
            }
        ]
    }

def create_young_adult_node() -> Dict[str, Any]:
    """Create node for young adult quotes."""
    return {
        "name": "young_adult",
        "task_messages": [
            {
                "role": "system",
                "content": "Explain our special young adult coverage options."
            }
        ],
        "functions": [...]  # Additional quote-specific functions
    }

def create_standard_node() -> Dict[str, Any]:
    """Create node for standard quotes."""
    return {
        "name": "standard",
        "task_messages": [
            {
                "role": "system",
                "content": "Present our standard coverage options."
            }
        ],
        "functions": [...]  # Additional quote-specific functions
    }

# Initialize flow manager
flow_manager = FlowManager(
    task=task,
    llm=llm,
    context_aggregator=context_aggregator,
)

@transport.event_handler("on_first_participant_joined")
async def on_first_participant_joined(transport, participant):
    await transport.capture_participant_transcription(participant["id"])
    await flow_manager.initialize(create_initial_node())
```

### Best Practices

- Store shared data in flow_manager.state
- Create separate functions for node creation

# Flow Editor

The Pipecat Flow Editor provides a visual interface for creating and managing conversation flows. It offers a node-based interface that makes it easier to design, visualize, and modify your flows.

<Frame>![Food Ordering Flow](/images/food-ordering-flow.png)</Frame>

## Visual Design

### Node Types

- **Start Node** (Green): Entry point of your flow

  ```python
  "greeting": {
      "role_messages": [...],
      "task_messages": [...],
      "functions": [...]
  }
  ```

- **Flow Nodes** (Blue): Intermediate states

  ```python
  "collect_info": {
      "task_messages": [...],
      "functions": [...],
      "pre_actions": [...]
  }
  ```

- **End Node** (Red): Final state

  ```python
  "end": {
      "task_messages": [...],
      "functions": [],
      "post_actions": [{"type": "end_conversation"}]
  }
  ```

- **Function Nodes**:
  - Edge Functions (Purple): Create transitions
    ```python
    {
        "name": "next_node",
        "description": "Transition to next state"
    }
    ```
  - Node Functions (Orange): Perform operations
    ```python
    {
        "name": "process_data",
        "handler": process_data_handler,
        "description": "Process user data"
    }
    ```

## Naming Conventions

- **Start Node**: Use descriptive names (e.g., "greeting", "welcome")
- **Flow Nodes**: Name based on purpose (e.g., "collect_info", "verify_data")
- **End Node**: Conventionally named "end"
- **Functions**: Use clear, action-oriented names

### Function Configuration

```python
{
    "type": "function",
    "function": {
        "name": "process_data",
        "handler": process_handler,
        "description": "Process user data",
        "parameters": {...}
    }
}
```

When using the Flow Editor, function handlers can be specified using the `__function__:` token:

```python
{
    "type": "function",
    "function": {
        "name": "process_data",
        "handler": "__function__:process_data",  # References function in main script
        "description": "Process user data",
        "parameters": {...}
    }
}
```

The handler will be looked up in your main script when the flow is executed.

<Note>
  When function handlers are specified in the flow editor, they will be exported
  with the `__function__:` token.
</Note>

## Using the Editor

### Creating a New Flow

1. Start with a descriptively named Start Node
2. Add Flow Nodes for each conversation state
3. Connect nodes using Edge Functions
4. Add Node Functions for operations
5. Include an End Node

### Import/Export

```python
# Export format
{
    "initial_node": "greeting",
    "nodes": {
        "greeting": {
            "role_messages": [...],
            "task_messages": [...],
            "functions": [...],
            "pre_actions": [...]
        },
        "process": {
            "task_messages": [...],
            "functions": [...],
        },
        "end": {
            "task_messages": [...],
            "functions": [],
            "post_actions": [...]
        }
    }
}
```

### Tips

- Use the visual preview to verify flow logic
- Test exported configurations
- Document node purposes and transitions
- Keep flows modular and maintainable

Try the editor at [flows.pipecat.ai](https://flows.pipecat.ai)
